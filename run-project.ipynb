{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f8a5dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import os, sys\n",
    "import yaml\n",
    "from argparse import ArgumentParser\n",
    "from time import gmtime, strftime\n",
    "from shutil import copy\n",
    "\n",
    "from frames_dataset import FramesDataset\n",
    "\n",
    "from modules.generator import OcclusionAwareGenerator\n",
    "from modules.discriminator import MultiScaleDiscriminator\n",
    "from modules.keypoint_detector import KPDetector\n",
    "\n",
    "import torch\n",
    "\n",
    "from train import train\n",
    "from reconstruction import reconstruction\n",
    "from animate import animate\n",
    "\n",
    "# Code cell <undefined>\n",
    "# %% [code]\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import os, sys\n",
    "import yaml\n",
    "from argparse import ArgumentParser\n",
    "from time import gmtime, strftime\n",
    "from shutil import copy\n",
    "\n",
    "from frames_dataset import FramesDataset\n",
    "\n",
    "from modules.generator import OcclusionAwareGenerator\n",
    "from modules.discriminator import MultiScaleDiscriminator\n",
    "from modules.keypoint_detector import KPDetector\n",
    "\n",
    "import torch\n",
    "\n",
    "from train import train\n",
    "from reconstruction import reconstruction\n",
    "from animate import animate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4490d649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5fb9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [0]\n",
    "f=r'config/mgif-256.yaml'\n",
    "\n",
    "with open(f, \"r\") as stream:\n",
    "  try:\n",
    "      config = yaml.safe_load(stream)\n",
    "  except yaml.YAMLError as e:\n",
    "      print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aefdfc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "log_dir = os.path.join('log', os.path.basename('mgif-256.yaml').split('.')[0])\n",
    "log_dir += ' ' + strftime(\"%d_%m_%y_%H.%M.%S\", gmtime())\n",
    "\n",
    "generator = OcclusionAwareGenerator(**config['model_params']['generator_params'],\n",
    "                                    **config['model_params']['common_params'])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    generator.to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff67588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = MultiScaleDiscriminator(**config['model_params']['discriminator_params'],\n",
    "                                            **config['model_params']['common_params'])\n",
    "if torch.cuda.is_available():\n",
    "  discriminator.to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2a59c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_detector = KPDetector(**config['model_params']['kp_detector_params'],\n",
    "                             **config['model_params']['common_params'])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    kp_detector.to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6fd4515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use predefined train-test split.\n"
     ]
    }
   ],
   "source": [
    "dataset = FramesDataset(is_train=True, **config['dataset_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12659085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/ext3/miniconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/ext3/miniconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]/ext3/miniconda3/lib/python3.10/site-packages/torch/nn/functional.py:4236: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "100%|██████████| 50/50 [3:36:06<00:00, 259.33s/it]  \n"
     ]
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "train(config, generator, discriminator, kp_detector, None, log_dir, dataset, device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b05e0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use predefined train-test split.\n"
     ]
    }
   ],
   "source": [
    "dataset1 = FramesDataset(is_train=False, **config['dataset_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9987f6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from logger import Logger, Visualizer\n",
    "import numpy as np\n",
    "import imageio\n",
    "from sync_batchnorm import DataParallelWithCallback\n",
    "\n",
    "\n",
    "def reconstruction(config, generator, kp_detector, checkpoint, log_dir, dataset):\n",
    "    png_dir = os.path.join(log_dir, 'reconstruction/png')\n",
    "    log_dir = os.path.join(log_dir, 'reconstruction')\n",
    "\n",
    "    # if checkpoint is not None:\n",
    "    #     Logger.load_cpk(checkpoint, generator=generator, kp_detector=kp_detector)\n",
    "    # else:\n",
    "    #     raise AttributeError(\"Checkpoint should be specified for mode='reconstruction'.\")\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    if not os.path.exists(png_dir):\n",
    "        os.makedirs(png_dir)\n",
    "\n",
    "    loss_list = []\n",
    "    if torch.cuda.is_available():\n",
    "        generator = DataParallelWithCallback(generator)\n",
    "        kp_detector = DataParallelWithCallback(kp_detector)\n",
    "\n",
    "    generator.eval()\n",
    "    kp_detector.eval()\n",
    "\n",
    "    for it, x in tqdm(enumerate(dataloader)):\n",
    "        if config['reconstruction_params']['num_videos'] is not None:\n",
    "            if it > config['reconstruction_params']['num_videos']:\n",
    "                break\n",
    "        with torch.no_grad():\n",
    "            predictions = []\n",
    "            visualizations = []\n",
    "            if torch.cuda.is_available():\n",
    "                x['video'] = x['video'].cuda()\n",
    "            kp_source = kp_detector(x['video'][:, :, 0])\n",
    "            for frame_idx in range(x['video'].shape[2]):\n",
    "                source = x['video'][:, :, 0]\n",
    "                driving = x['video'][:, :, frame_idx]\n",
    "                kp_driving = kp_detector(driving)\n",
    "                out = generator(source, kp_source=kp_source, kp_driving=kp_driving)\n",
    "                out['kp_source'] = kp_source\n",
    "                out['kp_driving'] = kp_driving\n",
    "                del out['sparse_deformed']\n",
    "                predictions.append(np.transpose(out['prediction'].data.cpu().numpy(), [0, 2, 3, 1])[0])\n",
    "\n",
    "                visualization = Visualizer(**config['visualizer_params']).visualize(source=source,\n",
    "                                                                                    driving=driving, out=out)\n",
    "                visualizations.append(visualization)\n",
    "\n",
    "                loss_list.append(torch.abs(out['prediction'] - driving).mean().cpu().numpy())\n",
    "\n",
    "            predictions = np.concatenate(predictions, axis=1)\n",
    "            imageio.imsave(os.path.join(png_dir, x['name'][0] + '.png'), (255 * predictions).astype(np.uint8))\n",
    "\n",
    "            image_name = x['name'][0] + config['reconstruction_params']['format']\n",
    "            imageio.mimsave(os.path.join(log_dir, image_name), visualizations)\n",
    "\n",
    "    print(\"Reconstruction loss: %s\" % np.mean(loss_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9d7d103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [02:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction loss: 0.03144093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reconstruction(config, generator, kp_detector, None, log_dir, dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c186aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [01:28,  1.76s/it]\n"
     ]
    }
   ],
   "source": [
    "animate(config, generator, kp_detector, None, log_dir, dataset1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
